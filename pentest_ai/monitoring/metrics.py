"""
Monitoring and Metrics System for Pentest AI

Provides comprehensive monitoring, metrics collection, and alerting capabilities
with Prometheus integration and custom metrics.
"""

import time
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from collections import defaultdict, deque
import threading
import json

from prometheus_client import (
    Counter, Gauge, Histogram, Summary, Info,
    generate_latest, CONTENT_TYPE_LATEST,
    CollectorRegistry, multiprocess
)
import psutil

from ..core import (
    GraphDatabase,
    AuditLogger,
    EventType,
    LogLevel
)

logger = logging.getLogger(__name__)


@dataclass
class MetricPoint:
    """Individual metric data point"""
    timestamp: float
    value: float
    labels: Dict[str, str] = field(default_factory=dict)


@dataclass
class AlertRule:
    """Alert rule configuration"""
    name: str
    metric: str
    condition: str  # e.g., "> 100", "< 0.5"
    duration: str  # e.g., "5m", "1h"
    severity: str  # "info", "warning", "critical"
    message: str
    enabled: bool = True


class MetricsCollector:
    """Base metrics collector"""
    
    def __init__(self, name: str):
        self.name = name
        self.metrics: Dict[str, Any] = {}
    
    async def collect(self) -> Dict[str, float]:
        """Collect metrics - to be implemented by subclasses"""
        raise NotImplementedError
    
    def get_metric_names(self) -> List[str]:
        """Get list of metric names"""
        return list(self.metrics.keys())


class SystemMetricsCollector(MetricsCollector):
    """System-level metrics collector"""
    
    def __init__(self):
        super().__init__("system")
        
        # Initialize Prometheus metrics
        self.metrics = {
            "cpu_usage": Gauge("pentest_ai_cpu_usage_percent", "CPU usage percentage"),
            "memory_usage": Gauge("pentest_ai_memory_usage_bytes", "Memory usage in bytes"),
            "memory_percent": Gauge("pentest_ai_memory_usage_percent", "Memory usage percentage"),
            "disk_usage": Gauge("pentest_ai_disk_usage_bytes", "Disk usage in bytes"),
            "disk_percent": Gauge("pentest_ai_disk_usage_percent", "Disk usage percentage"),
            "network_sent": Gauge("pentest_ai_network_sent_bytes", "Network bytes sent"),
            "network_recv": Gauge("pentest_ai_network_recv_bytes", "Network bytes received"),
            "process_count": Gauge("pentest_ai_process_count", "Number of running processes"),
            "uptime": Gauge("pentest_ai_uptime_seconds", "System uptime in seconds")
        }
    
    async def collect(self) -> Dict[str, float]:
        """Collect system metrics"""
        try:
            # CPU usage
            cpu_percent = psutil.cpu_percent(interval=1)
            self.metrics["cpu_usage"].set(cpu_percent)
            
            # Memory usage
            memory = psutil.virtual_memory()
            self.metrics["memory_usage"].set(memory.used)
            self.metrics["memory_percent"].set(memory.percent)
            
            # Disk usage
            disk = psutil.disk_usage('/')
            self.metrics["disk_usage"].set(disk.used)
            self.metrics["disk_percent"].set((disk.used / disk.total) * 100)
            
            # Network usage
            network = psutil.net_io_counters()
            self.metrics["network_sent"].set(network.bytes_sent)
            self.metrics["network_recv"].set(network.bytes_recv)
            
            # Process count
            process_count = len(psutil.pids())
            self.metrics["process_count"].set(process_count)
            
            # Uptime
            uptime = time.time() - psutil.boot_time()
            self.metrics["uptime"].set(uptime)
            
            return {
                "cpu_usage": cpu_percent,
                "memory_usage": memory.used,
                "memory_percent": memory.percent,
                "disk_usage": disk.used,
                "disk_percent": (disk.used / disk.total) * 100,
                "network_sent": network.bytes_sent,
                "network_recv": network.bytes_recv,
                "process_count": process_count,
                "uptime": uptime
            }
        
        except Exception as e:
            logger.error(f"Failed to collect system metrics: {e}")
            return {}


class ApplicationMetricsCollector(MetricsCollector):
    """Application-specific metrics collector"""
    
    def __init__(self, graph_db: GraphDatabase, audit_logger: AuditLogger):
        super().__init__("application")
        self.graph_db = graph_db
        self.audit_logger = audit_logger
        
        # Initialize Prometheus metrics
        self.metrics = {
            "workflows_total": Counter("pentest_ai_workflows_total", "Total number of workflows", ["status"]),
            "workflows_active": Gauge("pentest_ai_workflows_active", "Number of active workflows"),
            "targets_total": Gauge("pentest_ai_targets_total", "Total number of targets"),
            "vulnerabilities_total": Gauge("pentest_ai_vulnerabilities_total", "Total vulnerabilities found", ["severity"]),
            "credentials_total": Gauge("pentest_ai_credentials_total", "Total credentials discovered"),
            "sessions_total": Gauge("pentest_ai_sessions_total", "Total sessions created"),
            "audit_events_total": Counter("pentest_ai_audit_events_total", "Total audit events", ["event_type", "level"]),
            "api_requests_total": Counter("pentest_ai_api_requests_total", "Total API requests", ["endpoint", "method", "status"]),
            "api_request_duration": Histogram("pentest_ai_api_request_duration_seconds", "API request duration", ["endpoint"]),
            "container_operations_total": Counter("pentest_ai_container_operations_total", "Container operations", ["operation", "status"]),
            "llm_requests_total": Counter("pentest_ai_llm_requests_total", "LLM requests", ["provider", "model"]),
            "llm_request_duration": Histogram("pentest_ai_llm_request_duration_seconds", "LLM request duration", ["provider"]),
            "safety_checks_total": Counter("pentest_ai_safety_checks_total", "Safety checks performed", ["result"]),
            "reports_generated_total": Counter("pentest_ai_reports_generated_total", "Reports generated", ["format"])
        }
    
    async def collect(self) -> Dict[str, float]:
        """Collect application metrics"""
        try:
            metrics = {}
            
            # Get workflow statistics
            workflows = await self._get_workflow_stats()
            metrics.update(workflows)
            
            # Get target statistics
            targets = await self._get_target_stats()
            metrics.update(targets)
            
            # Get vulnerability statistics
            vulnerabilities = await self._get_vulnerability_stats()
            metrics.update(vulnerabilities)
            
            # Get credential statistics
            credentials = await self._get_credential_stats()
            metrics.update(credentials)
            
            # Get session statistics
            sessions = await self._get_session_stats()
            metrics.update(sessions)
            
            # Get audit event statistics
            audit_events = await self._get_audit_stats()
            metrics.update(audit_events)
            
            return metrics
        
        except Exception as e:
            logger.error(f"Failed to collect application metrics: {e}")
            return {}
    
    async def _get_workflow_stats(self) -> Dict[str, float]:
        """Get workflow statistics"""
        try:
            # This would query the graph database for workflow stats
            # For now, return mock data
            return {
                "workflows_total": 25.0,
                "workflows_active": 3.0,
                "workflows_completed": 20.0,
                "workflows_failed": 2.0
            }
        except Exception as e:
            logger.error(f"Failed to get workflow stats: {e}")
            return {}
    
    async def _get_target_stats(self) -> Dict[str, float]:
        """Get target statistics"""
        try:
            # This would query the graph database for target stats
            return {
                "targets_total": 15.0,
                "targets_active": 12.0,
                "targets_completed": 10.0
            }
        except Exception as e:
            logger.error(f"Failed to get target stats: {e}")
            return {}
    
    async def _get_vulnerability_stats(self) -> Dict[str, float]:
        """Get vulnerability statistics"""
        try:
            # This would query the graph database for vulnerability stats
            return {
                "vulnerabilities_total": 45.0,
                "vulnerabilities_critical": 3.0,
                "vulnerabilities_high": 12.0,
                "vulnerabilities_medium": 20.0,
                "vulnerabilities_low": 10.0
            }
        except Exception as e:
            logger.error(f"Failed to get vulnerability stats: {e}")
            return {}
    
    async def _get_credential_stats(self) -> Dict[str, float]:
        """Get credential statistics"""
        try:
            # This would query the graph database for credential stats
            return {
                "credentials_total": 8.0,
                "credentials_weak": 5.0,
                "credentials_default": 3.0
            }
        except Exception as e:
            logger.error(f"Failed to get credential stats: {e}")
            return {}
    
    async def _get_session_stats(self) -> Dict[str, float]:
        """Get session statistics"""
        try:
            # This would query the graph database for session stats
            return {
                "sessions_total": 30.0,
                "sessions_active": 5.0,
                "sessions_completed": 25.0
            }
        except Exception as e:
            logger.error(f"Failed to get session stats: {e}")
            return {}
    
    async def _get_audit_stats(self) -> Dict[str, float]:
        """Get audit event statistics"""
        try:
            # This would query the audit logger for event stats
            return {
                "audit_events_total": 1500.0,
                "audit_events_info": 1200.0,
                "audit_events_warning": 250.0,
                "audit_events_error": 50.0
            }
        except Exception as e:
            logger.error(f"Failed to get audit stats: {e}")
            return {}


class SecurityMetricsCollector(MetricsCollector):
    """Security-specific metrics collector"""
    
    def __init__(self):
        super().__init__("security")
        
        # Initialize Prometheus metrics
        self.metrics = {
            "security_incidents_total": Counter("pentest_ai_security_incidents_total", "Security incidents", ["severity", "type"]),
            "failed_login_attempts": Counter("pentest_ai_failed_login_attempts_total", "Failed login attempts"),
            "suspicious_activities": Counter("pentest_ai_suspicious_activities_total", "Suspicious activities detected"),
            "safety_violations": Counter("pentest_ai_safety_violations_total", "Safety violations", ["type"]),
            "unauthorized_access": Counter("pentest_ai_unauthorized_access_total", "Unauthorized access attempts"),
            "data_exfiltration_attempts": Counter("pentest_ai_data_exfiltration_attempts_total", "Data exfiltration attempts"),
            "malware_detected": Counter("pentest_ai_malware_detected_total", "Malware detected"),
            "vulnerability_exploits": Counter("pentest_ai_vulnerability_exploits_total", "Vulnerability exploitation attempts"),
            "network_anomalies": Counter("pentest_ai_network_anomalies_total", "Network anomalies detected"),
            "compliance_violations": Counter("pentest_ai_compliance_violations_total", "Compliance violations", ["standard"])
        }
    
    async def collect(self) -> Dict[str, float]:
        """Collect security metrics"""
        try:
            # This would collect security-specific metrics
            # For now, return mock data
            return {
                "security_incidents_total": 5.0,
                "failed_login_attempts": 12.0,
                "suspicious_activities": 3.0,
                "safety_violations": 2.0,
                "unauthorized_access": 1.0,
                "data_exfiltration_attempts": 0.0,
                "malware_detected": 0.0,
                "vulnerability_exploits": 8.0,
                "network_anomalies": 2.0,
                "compliance_violations": 0.0
            }
        
        except Exception as e:
            logger.error(f"Failed to collect security metrics: {e}")
            return {}


class MetricsManager:
    """Main metrics management system"""
    
    def __init__(
        self,
        graph_db: GraphDatabase,
        audit_logger: AuditLogger,
        collection_interval: int = 60
    ):
        self.graph_db = graph_db
        self.audit_logger = audit_logger
        self.collection_interval = collection_interval
        
        # Initialize collectors
        self.collectors = {
            "system": SystemMetricsCollector(),
            "application": ApplicationMetricsCollector(graph_db, audit_logger),
            "security": SecurityMetricsCollector()
        }
        
        # Metrics storage
        self.metrics_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        self.current_metrics: Dict[str, Dict[str, float]] = {}
        
        # Alerting
        self.alert_rules: List[AlertRule] = []
        self.active_alerts: Dict[str, Dict[str, Any]] = {}
        
        # Threading
        self.collection_thread: Optional[threading.Thread] = None
        self.running = False
        
        # Initialize default alert rules
        self._init_default_alerts()
    
    def _init_default_alerts(self):
        """Initialize default alert rules"""
        self.alert_rules = [
            AlertRule(
                name="high_cpu_usage",
                metric="system.cpu_usage",
                condition="> 80",
                duration="5m",
                severity="warning",
                message="CPU usage is above 80% for 5 minutes"
            ),
            AlertRule(
                name="high_memory_usage",
                metric="system.memory_percent",
                condition="> 90",
                duration="5m",
                severity="critical",
                message="Memory usage is above 90% for 5 minutes"
            ),
            AlertRule(
                name="high_disk_usage",
                metric="system.disk_percent",
                condition="> 85",
                duration="10m",
                severity="warning",
                message="Disk usage is above 85% for 10 minutes"
            ),
            AlertRule(
                name="workflow_failure_rate",
                metric="application.workflows_failed",
                condition="> 5",
                duration="1h",
                severity="warning",
                message="High workflow failure rate detected"
            ),
            AlertRule(
                name="security_incident",
                metric="security.security_incidents_total",
                condition="> 0",
                duration="1m",
                severity="critical",
                message="Security incident detected"
            )
        ]
    
    async def start(self):
        """Start metrics collection"""
        if self.running:
            logger.warning("Metrics collection already running")
            return
        
        self.running = True
        self.collection_thread = threading.Thread(target=self._collection_loop, daemon=True)
        self.collection_thread.start()
        
        logger.info("Metrics collection started")
        
        # Log startup event
        await self.audit_logger.log_event(
            event_type=EventType.SYSTEM_START,
            level=LogLevel.INFO,
            user_id="system",
            message="Metrics collection system started",
            details={"collection_interval": self.collection_interval}
        )
    
    async def stop(self):
        """Stop metrics collection"""
        self.running = False
        
        if self.collection_thread:
            self.collection_thread.join(timeout=5)
        
        logger.info("Metrics collection stopped")
        
        # Log shutdown event
        await self.audit_logger.log_event(
            event_type=EventType.SYSTEM_SHUTDOWN,
            level=LogLevel.INFO,
            user_id="system",
            message="Metrics collection system stopped"
        )
    
    def _collection_loop(self):
        """Main collection loop"""
        while self.running:
            try:
                # Run collection in asyncio event loop
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(self._collect_all_metrics())
                loop.close()
                
                # Sleep for collection interval
                time.sleep(self.collection_interval)
            
            except Exception as e:
                logger.error(f"Error in metrics collection loop: {e}")
                time.sleep(10)  # Short sleep on error
    
    async def _collect_all_metrics(self):
        """Collect metrics from all collectors"""
        try:
            all_metrics = {}
            
            for collector_name, collector in self.collectors.items():
                metrics = await collector.collect()
                all_metrics[collector_name] = metrics
                
                # Store in history
                timestamp = time.time()
                for metric_name, value in metrics.items():
                    full_metric_name = f"{collector_name}.{metric_name}"
                    self.metrics_history[full_metric_name].append(
                        MetricPoint(timestamp=timestamp, value=value)
                    )
            
            self.current_metrics = all_metrics
            
            # Check alerts
            await self._check_alerts()
            
            # Log metrics collection
            await self.audit_logger.log_event(
                event_type=EventType.DATA_ACCESS,
                level=LogLevel.DEBUG,
                user_id="system",
                message="Metrics collected",
                details={"metrics_count": sum(len(m) for m in all_metrics.values())}
            )
        
        except Exception as e:
            logger.error(f"Failed to collect metrics: {e}")
    
    async def _check_alerts(self):
        """Check alert rules against current metrics"""
        try:
            for rule in self.alert_rules:
                if not rule.enabled:
                    continue
                
                # Get metric value
                metric_value = self._get_metric_value(rule.metric)
                if metric_value is None:
                    continue
                
                # Check condition
                if self._evaluate_condition(metric_value, rule.condition):
                    # Check duration
                    if await self._check_duration(rule.metric, rule.condition, rule.duration):
                        await self._trigger_alert(rule, metric_value)
                else:
                    # Clear alert if condition is no longer met
                    await self._clear_alert(rule.name)
        
        except Exception as e:
            logger.error(f"Failed to check alerts: {e}")
    
    def _get_metric_value(self, metric_name: str) -> Optional[float]:
        """Get current value for a metric"""
        try:
            parts = metric_name.split('.')
            if len(parts) != 2:
                return None
            
            collector_name, metric_name = parts
            if collector_name not in self.current_metrics:
                return None
            
            return self.current_metrics[collector_name].get(metric_name)
        
        except Exception as e:
            logger.error(f"Failed to get metric value: {e}")
            return None
    
    def _evaluate_condition(self, value: float, condition: str) -> bool:
        """Evaluate a condition against a value"""
        try:
            operator = condition[0]
            threshold = float(condition[1:].strip())
            
            if operator == '>':
                return value > threshold
            elif operator == '<':
                return value < threshold
            elif operator == '>=':
                return value >= threshold
            elif operator == '<=':
                return value <= threshold
            elif operator == '=':
                return value == threshold
            else:
                return False
        
        except Exception as e:
            logger.error(f"Failed to evaluate condition: {e}")
            return False
    
    async def _check_duration(self, metric_name: str, condition: str, duration: str) -> bool:
        """Check if condition has been met for the specified duration"""
        try:
            # Parse duration (e.g., "5m", "1h")
            duration_seconds = self._parse_duration(duration)
            cutoff_time = time.time() - duration_seconds
            
            # Get metric history
            metric_history = self.metrics_history.get(metric_name, deque())
            
            # Check if condition has been met for the duration
            condition_met_count = 0
            for point in reversed(metric_history):
                if point.timestamp < cutoff_time:
                    break
                
                if self._evaluate_condition(point.value, condition):
                    condition_met_count += 1
                else:
                    break
            
            # Check if condition was met for the entire duration
            return condition_met_count >= (duration_seconds / self.collection_interval)
        
        except Exception as e:
            logger.error(f"Failed to check duration: {e}")
            return False
    
    def _parse_duration(self, duration: str) -> int:
        """Parse duration string to seconds"""
        try:
            if duration.endswith('s'):
                return int(duration[:-1])
            elif duration.endswith('m'):
                return int(duration[:-1]) * 60
            elif duration.endswith('h'):
                return int(duration[:-1]) * 3600
            elif duration.endswith('d'):
                return int(duration[:-1]) * 86400
            else:
                return int(duration)
        except:
            return 60  # Default to 1 minute
    
    async def _trigger_alert(self, rule: AlertRule, metric_value: float):
        """Trigger an alert"""
        try:
            alert_id = f"{rule.name}_{int(time.time())}"
            
            # Check if alert is already active
            if rule.name in self.active_alerts:
                return  # Alert already active
            
            alert = {
                "id": alert_id,
                "rule": rule,
                "metric_value": metric_value,
                "triggered_at": datetime.utcnow(),
                "status": "active"
            }
            
            self.active_alerts[rule.name] = alert
            
            # Log alert
            await self.audit_logger.log_event(
                event_type=EventType.SECURITY_ALERT,
                level=LogLevel.WARNING if rule.severity == "warning" else LogLevel.ERROR,
                user_id="system",
                message=f"Alert triggered: {rule.message}",
                details={
                    "alert_id": alert_id,
                    "rule_name": rule.name,
                    "metric": rule.metric,
                    "condition": rule.condition,
                    "severity": rule.severity,
                    "metric_value": metric_value
                }
            )
            
            logger.warning(f"Alert triggered: {rule.name} - {rule.message}")
        
        except Exception as e:
            logger.error(f"Failed to trigger alert: {e}")
    
    async def _clear_alert(self, rule_name: str):
        """Clear an active alert"""
        try:
            if rule_name in self.active_alerts:
                alert = self.active_alerts[rule_name]
                alert["status"] = "resolved"
                alert["resolved_at"] = datetime.utcnow()
                
                # Log alert resolution
                await self.audit_logger.log_event(
                    event_type=EventType.SECURITY_ALERT,
                    level=LogLevel.INFO,
                    user_id="system",
                    message=f"Alert resolved: {alert['rule'].message}",
                    details={
                        "alert_id": alert["id"],
                        "rule_name": rule_name,
                        "duration": (alert["resolved_at"] - alert["triggered_at"]).total_seconds()
                    }
                )
                
                logger.info(f"Alert resolved: {rule_name}")
        
        except Exception as e:
            logger.error(f"Failed to clear alert: {e}")
    
    async def get_current_metrics(self) -> Dict[str, Dict[str, float]]:
        """Get current metrics"""
        return self.current_metrics
    
    async def get_metric_history(
        self,
        metric_name: str,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None
    ) -> List[MetricPoint]:
        """Get metric history"""
        try:
            history = self.metrics_history.get(metric_name, deque())
            
            if start_time or end_time:
                filtered_history = []
                start_timestamp = start_time.timestamp() if start_time else 0
                end_timestamp = end_time.timestamp() if end_time else time.time()
                
                for point in history:
                    if start_timestamp <= point.timestamp <= end_timestamp:
                        filtered_history.append(point)
                
                return filtered_history
            
            return list(history)
        
        except Exception as e:
            logger.error(f"Failed to get metric history: {e}")
            return []
    
    async def get_active_alerts(self) -> List[Dict[str, Any]]:
        """Get active alerts"""
        return [
            {**alert, "rule_name": rule_name}
            for rule_name, alert in self.active_alerts.items()
            if alert["status"] == "active"
        ]
    
    async def add_alert_rule(self, rule: AlertRule) -> bool:
        """Add a new alert rule"""
        try:
            self.alert_rules.append(rule)
            
            # Log rule addition
            await self.audit_logger.log_event(
                event_type=EventType.CONFIGURATION_CHANGE,
                level=LogLevel.INFO,
                user_id="system",
                message=f"Alert rule added: {rule.name}",
                details=rule.__dict__
            )
            
            return True
        
        except Exception as e:
            logger.error(f"Failed to add alert rule: {e}")
            return False
    
    async def remove_alert_rule(self, rule_name: str) -> bool:
        """Remove an alert rule"""
        try:
            self.alert_rules = [rule for rule in self.alert_rules if rule.name != rule_name]
            
            # Log rule removal
            await self.audit_logger.log_event(
                event_type=EventType.CONFIGURATION_CHANGE,
                level=LogLevel.INFO,
                user_id="system",
                message=f"Alert rule removed: {rule_name}"
            )
            
            return True
        
        except Exception as e:
            logger.error(f"Failed to remove alert rule: {e}")
            return False
    
    def get_prometheus_metrics(self) -> str:
        """Get Prometheus-formatted metrics"""
        try:
            return generate_latest()
        except Exception as e:
            logger.error(f"Failed to generate Prometheus metrics: {e}")
            return ""
    
    async def get_metrics_summary(self) -> Dict[str, Any]:
        """Get metrics summary for dashboard"""
        try:
            summary = {
                "system": {
                    "cpu_usage": self.current_metrics.get("system", {}).get("cpu_usage", 0),
                    "memory_usage": self.current_metrics.get("system", {}).get("memory_percent", 0),
                    "disk_usage": self.current_metrics.get("system", {}).get("disk_percent", 0),
                    "uptime": self.current_metrics.get("system", {}).get("uptime", 0)
                },
                "application": {
                    "workflows_active": self.current_metrics.get("application", {}).get("workflows_active", 0),
                    "targets_total": self.current_metrics.get("application", {}).get("targets_total", 0),
                    "vulnerabilities_total": self.current_metrics.get("application", {}).get("vulnerabilities_total", 0),
                    "credentials_total": self.current_metrics.get("application", {}).get("credentials_total", 0)
                },
                "security": {
                    "security_incidents": self.current_metrics.get("security", {}).get("security_incidents_total", 0),
                    "failed_logins": self.current_metrics.get("security", {}).get("failed_login_attempts", 0),
                    "suspicious_activities": self.current_metrics.get("security", {}).get("suspicious_activities", 0)
                },
                "alerts": {
                    "active": len([a for a in self.active_alerts.values() if a["status"] == "active"]),
                    "total_rules": len(self.alert_rules)
                },
                "collection": {
                    "last_update": datetime.utcnow().isoformat(),
                    "interval": self.collection_interval,
                    "running": self.running
                }
            }
            
            return summary
        
        except Exception as e:
            logger.error(f"Failed to get metrics summary: {e}")
            return {}