"""
Core pentesting agent that orchestrates multi-domain security assessments.
"""

import asyncio
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

from ..io import InputOutput
from ..models import ModelSettings
from .config import PentestConfig
from .agents.coordinator import AgentCoordinator
from .tools.orchestrator import ToolOrchestrator
from .workflows.manager import WorkflowManager
from .graph.database import GraphDatabase
from .intel.vulnerability import VulnerabilityIntel
from .compliance.guardian import ComplianceGuardian
from .reporting.api import ReportingAPI


class PentestAgent:
    """
    Main pentesting agent that coordinates all security assessment activities.
    """
    
    def __init__(self, config: Optional[PentestConfig] = None, io: Optional[InputOutput] = None):
        """Initialize the pentesting agent."""
        self.config = config or PentestConfig()
        self.io = io or InputOutput()
        
        # Set up logging
        self.logger = self._setup_logging()
        
        # Initialize core components
        self.coordinator = AgentCoordinator(self.config, self.io)
        self.tool_orchestrator = ToolOrchestrator(self.config)
        self.workflow_manager = WorkflowManager(self.config)
        self.graph_db = GraphDatabase(self.config)
        self.vuln_intel = VulnerabilityIntel(self.config)
        self.compliance_guardian = ComplianceGuardian(self.config)
        self.reporting_api = ReportingAPI(self.config)
        
        # Track assessment state
        self.current_assessment = None
        self.assessment_results = {}
        
    def _setup_logging(self) -> logging.Logger:
        """Set up logging for the pentesting agent."""
        logger = logging.getLogger("pentest_agent")
        logger.setLevel(logging.INFO)
        
        # Create console handler
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # Add file handler for audit logging
        if self.config.security_config.audit_log_enabled:
            file_handler = logging.FileHandler(self.config.security_config.audit_log_path)
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)
        
        return logger
    
    async def initialize(self):
        """Initialize all components and perform setup checks."""
        self.logger.info("Initializing Aider Pentesting Agent...")
        
        # Check security compliance
        if not await self.compliance_guardian.verify_setup():
            raise RuntimeError("Security compliance verification failed")
        
        # Initialize graph database
        await self.graph_db.initialize()
        
        # Initialize vulnerability intelligence
        await self.vuln_intel.initialize()
        
        # Set up tool orchestration
        if self.config.tool_config.auto_install:
            await self.tool_orchestrator.install_core_tools()
        
        # Start reporting API if enabled
        if self.config.report_api_enabled:
            await self.reporting_api.start()
        
        self.logger.info("Pentesting agent initialized successfully")
    
    async def run_assessment(self, target: str, assessment_type: str = "full", 
                           workflow_template: Optional[str] = None) -> Dict[str, Any]:
        """
        Run a comprehensive security assessment.
        
        Args:
            target: Target system or network to assess
            assessment_type: Type of assessment (full, web, network, etc.)
            workflow_template: Specific workflow template to use
        
        Returns:
            Dictionary containing assessment results
        """
        # Verify consent and compliance
        if not await self.compliance_guardian.verify_consent(target):
            raise PermissionError(f"Assessment consent not granted for target: {target}")
        
        if not await self.compliance_guardian.check_target_allowed(target):
            raise PermissionError(f"Target not in allowed list: {target}")
        
        assessment_id = f"assessment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.logger.info(f"Starting assessment {assessment_id} on target: {target}")
        
        try:
            # Create assessment context
            self.current_assessment = {
                "id": assessment_id,
                "target": target,
                "type": assessment_type,
                "start_time": datetime.now(),
                "status": "running"
            }
            
            # Get or create workflow
            if workflow_template:
                workflow = await self.workflow_manager.load_template(workflow_template)
            else:
                workflow = await self.workflow_manager.create_workflow(assessment_type)
            
            # Initialize target in graph database
            await self.graph_db.add_target(target)
            
            # Run the assessment workflow
            results = await self.coordinator.execute_workflow(workflow, target)
            
            # Process and enrich results with vulnerability intelligence
            enriched_results = await self.vuln_intel.enrich_findings(results)
            
            # Store results in graph database
            await self.graph_db.store_assessment_results(assessment_id, enriched_results)
            
            # Generate reports
            reports = await self.reporting_api.generate_reports(enriched_results)
            
            # Update assessment status
            self.current_assessment["status"] = "completed"
            self.current_assessment["end_time"] = datetime.now()
            self.current_assessment["results"] = enriched_results
            self.current_assessment["reports"] = reports
            
            self.logger.info(f"Assessment {assessment_id} completed successfully")
            return self.current_assessment
            
        except Exception as e:
            self.logger.error(f"Assessment {assessment_id} failed: {str(e)}")
            if self.current_assessment:
                self.current_assessment["status"] = "failed"
                self.current_assessment["error"] = str(e)
            raise
        
        finally:
            # Cleanup and audit logging
            await self.compliance_guardian.log_assessment_completion(self.current_assessment)
    
    async def run_demo_campaign(self) -> Dict[str, Any]:
        """
        Run the demo campaign as specified in acceptance criteria:
        - OWASP Juice Shop
        - Metasploitable 2  
        - Phishing simulation
        """
        self.logger.info("Starting demo campaign...")
        
        demo_results = {}
        
        # OWASP Juice Shop assessment
        try:
            self.logger.info("Running OWASP Juice Shop assessment...")
            juice_shop_results = await self.run_assessment(
                target="http://localhost:3000",
                assessment_type="web",
                workflow_template="juice_shop"
            )
            demo_results["juice_shop"] = juice_shop_results
        except Exception as e:
            self.logger.error(f"Juice Shop assessment failed: {e}")
            demo_results["juice_shop"] = {"status": "failed", "error": str(e)}
        
        # Metasploitable 2 assessment
        try:
            self.logger.info("Running Metasploitable 2 assessment...")
            metasploitable_results = await self.run_assessment(
                target="192.168.1.100",
                assessment_type="network", 
                workflow_template="metasploitable"
            )
            demo_results["metasploitable"] = metasploitable_results
        except Exception as e:
            self.logger.error(f"Metasploitable assessment failed: {e}")
            demo_results["metasploitable"] = {"status": "failed", "error": str(e)}
        
        # Phishing simulation
        try:
            self.logger.info("Running phishing simulation...")
            phishing_results = await self.run_assessment(
                target="demo.company.com",
                assessment_type="social_engineering",
                workflow_template="phishing_sim"
            )
            demo_results["phishing"] = phishing_results
        except Exception as e:
            self.logger.error(f"Phishing simulation failed: {e}")
            demo_results["phishing"] = {"status": "failed", "error": str(e)}
        
        self.logger.info("Demo campaign completed")
        return demo_results
    
    async def get_status(self) -> Dict[str, Any]:
        """Get current agent status and metrics."""
        return {
            "agent_status": "running" if self.current_assessment else "idle",
            "current_assessment": self.current_assessment,
            "enabled_providers": [p.name for p in self.config.get_enabled_providers()],
            "available_tools": await self.tool_orchestrator.get_available_tools(),
            "workflow_templates": await self.workflow_manager.list_templates(),
            "compliance_status": await self.compliance_guardian.get_status()
        }
    
    async def shutdown(self):
        """Gracefully shutdown the pentesting agent."""
        self.logger.info("Shutting down pentesting agent...")
        
        if self.current_assessment and self.current_assessment["status"] == "running":
            self.logger.warning("Stopping running assessment...")
            self.current_assessment["status"] = "aborted"
            await self.compliance_guardian.log_assessment_completion(self.current_assessment)
        
        # Shutdown components
        await self.reporting_api.stop()
        await self.graph_db.close()
        
        self.logger.info("Pentesting agent shutdown complete")